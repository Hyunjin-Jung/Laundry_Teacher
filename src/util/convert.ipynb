{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "958bd18f-ca66-4f0d-a43f-71cae867af94",
   "metadata": {},
   "source": [
    "# Read all labels from train and validation label sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0852989-2be0-408f-aba8-b36bafb8d686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import math\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10b48769-2930-4dd4-90b6-081cb3d16531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadReducedLabelsFrom(path): # directory path\n",
    "    if os.path.isdir(path) and (\"TL_reduced\" in path or \"VL_reduced\" in path):\n",
    "        with os.scandir(path) as entries:\n",
    "            labels = []\n",
    "            start = time()\n",
    "            print(f\"Load all reduced json files in '{path}'\")\n",
    "            for entry in entries:\n",
    "                if os.path.isfile(entry) and \".json\" in entry.name:\n",
    "                    with open(path + entry.name, 'r', encoding=\"UTF-8\") as file:\n",
    "                        label = json.load(file)\n",
    "                        labels.append((path, label))\n",
    "        end = time()\n",
    "        print(f\"Finish loading all reduced json files in '{path}', elapsed = {end - start:.2f} sec(s)\")\n",
    "        return labels\n",
    "    else:\n",
    "        error_msg = \"ASSERTION FAILED:\"\n",
    "        if not os.path.isdir(path):\n",
    "            error_msg += f\" Path to label files must be a directory!\\n\"\n",
    "        elif not (\"TL_reduced\" in path or \"VL_reduced\" in path):\n",
    "            error_msg += f\" Path must have a reserved name ended with 'TL_reduced' or 'VL_reduced'!\\n\"\n",
    "        raise AssertionError(error_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e353b47-5384-4e0f-bd0c-5145672e85b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading files\n",
      "--------------------------------------------------------------------------------------\n",
      "Load all reduced json files in './../dataset/labels/train/TL_reduced/TL_blouse_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/train/TL_reduced/TL_blouse_reduced/', elapsed = 29.52 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/train/TL_reduced/TL_bottom_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/train/TL_reduced/TL_bottom_reduced/', elapsed = 100.99 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/train/TL_reduced/TL_cardigan_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/train/TL_reduced/TL_cardigan_reduced/', elapsed = 26.47 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/train/TL_reduced/TL_coat_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/train/TL_reduced/TL_coat_reduced/', elapsed = 36.04 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/train/TL_reduced/TL_jacket_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/train/TL_reduced/TL_jacket_reduced/', elapsed = 33.85 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/train/TL_reduced/TL_jumper_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/train/TL_reduced/TL_jumper_reduced/', elapsed = 40.90 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/train/TL_reduced/TL_onepiece_dress_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/train/TL_reduced/TL_onepiece_dress_reduced/', elapsed = 49.19 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/train/TL_reduced/TL_onepiece_jumpsuite_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/train/TL_reduced/TL_onepiece_jumpsuite_reduced/', elapsed = 1.32 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/train/TL_reduced/TL_shirt_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/train/TL_reduced/TL_shirt_reduced/', elapsed = 41.73 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/train/TL_reduced/TL_sweater_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/train/TL_reduced/TL_sweater_reduced/', elapsed = 30.12 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/train/TL_reduced/TL_t-shirt_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/train/TL_reduced/TL_t-shirt_reduced/', elapsed = 117.64 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/train/TL_reduced/TL_vest_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/train/TL_reduced/TL_vest_reduced/', elapsed = 24.85 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/val/VL_reduced/VL_blouse_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/val/VL_reduced/VL_blouse_reduced/', elapsed = 3.54 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/val/VL_reduced/VL_bottom_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/val/VL_reduced/VL_bottom_reduced/', elapsed = 13.06 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/val/VL_reduced/VL_cardigan_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/val/VL_reduced/VL_cardigan_reduced/', elapsed = 3.28 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/val/VL_reduced/VL_coat_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/val/VL_reduced/VL_coat_reduced/', elapsed = 4.53 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/val/VL_reduced/VL_jacket_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/val/VL_reduced/VL_jacket_reduced/', elapsed = 4.26 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/val/VL_reduced/VL_jumper_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/val/VL_reduced/VL_jumper_reduced/', elapsed = 5.09 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/val/VL_reduced/VL_onepiece_dress_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/val/VL_reduced/VL_onepiece_dress_reduced/', elapsed = 6.11 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/val/VL_reduced/VL_onepiece_jumpsuite_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/val/VL_reduced/VL_onepiece_jumpsuite_reduced/', elapsed = 0.16 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/val/VL_reduced/VL_shirt_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/val/VL_reduced/VL_shirt_reduced/', elapsed = 5.07 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/val/VL_reduced/VL_sweater_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/val/VL_reduced/VL_sweater_reduced/', elapsed = 3.82 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/val/VL_reduced/VL_t-shirt_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/val/VL_reduced/VL_t-shirt_reduced/', elapsed = 14.68 sec(s)\n",
      "Load all reduced json files in './../dataset/labels/val/VL_reduced/VL_vest_reduced/'\n",
      "Finish loading all reduced json files in './../dataset/labels/val/VL_reduced/VL_vest_reduced/', elapsed = 3.22 sec(s)\n",
      "Finish loading files, elapsed = 599.47 sec(s)\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "root = './../dataset/labels/'\n",
    "labels = []\n",
    "print(f\"Start loading files\")\n",
    "print(\"--------------------------------------------------------------------------------------\")\n",
    "start = time()\n",
    "with os.scandir(root) as dirs:\n",
    "    for dir in dirs:\n",
    "        if os.path.isdir(dir) and (dir.name == \"train\" or dir.name == \"val\"):\n",
    "            type = \"TL\" if dir.name == \"train\" else \"VL\"\n",
    "            path_reduced = root + dir.name + \"/\" + type + \"_reduced/\"\n",
    "            with os.scandir(path_reduced) as items:\n",
    "                for item in items:\n",
    "                    if not 'txt' in item.name:\n",
    "                        labels.extend(loadReducedLabelsFrom(path_reduced + item.name + '/'))\n",
    "end = time()\n",
    "print(f\"Finish loading files, elapsed = {end - start:.2f} sec(s)\")\n",
    "print(\"--------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51f0746-e43f-42d1-ad2e-238763617154",
   "metadata": {},
   "source": [
    "# Convert json files into yolov8 text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8803218-4d2a-434a-a920-aa637bd531a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return an normalized bounding-box of arbitrary points.\n",
    "def bbox(points, point_count, image_width, image_height):\n",
    "    # Find min and max points represented by integer numbers.\n",
    "    min_x = math.inf\n",
    "    min_y = min_x\n",
    "    max_x = -min_x\n",
    "    max_y = -min_y\n",
    "    for i in range(int(point_count)):\n",
    "        x, y = points[2*i], points[2*i+1]\n",
    "        min_x = x if x <= min_x else min_x\n",
    "        max_x = x if x > max_x else max_x\n",
    "        min_y = y if y <= min_y else min_y\n",
    "        max_y = y if y > max_y else max_y\n",
    "    # Calculate a bbox center, a bbox width, and a bbox height.\n",
    "    center_x = 0.5 * (min_x + max_x)\n",
    "    center_y = 0.5 * (min_y + max_y)\n",
    "    box_width = max_x - min_x\n",
    "    box_height = max_y - min_y\n",
    "    # Normalize the center and the bbox dimensions.\n",
    "    nx = center_x / image_width\n",
    "    ny = center_y / image_height\n",
    "    w = box_width / image_width\n",
    "    h = box_height / image_height\n",
    "    return (nx, ny, w, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234a1901-cb45-46e0-8051-e63c2690cfe1",
   "metadata": {},
   "source": [
    "# Class candidates\n",
    "\n",
    "    fiber composition =: [cotton | hemp | ... | synthetic fiber others]  \n",
    "    \n",
    "    washing method =: [hand washing30 | washing30 | ... | washing95]\n",
    "    \n",
    "    drycleaning =: [dryclean | dryclean : laundry | dryclean : petroleum solvent only]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0857e2b0-d090-483b-943d-81e18ce94ac4",
   "metadata": {},
   "source": [
    "# Version 1: Combined classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8489229d-eb70-4abc-9e8c-fc68258409f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 1\n",
    "fibers = {\n",
    "    # fiber composition\n",
    "    'cotton': 0,\n",
    "    'hemp': 1,\n",
    "    'cellulose fiber others': 2,\n",
    "    'silk': 3,\n",
    "    'wool': 4,\n",
    "    'protein fiber others': 5,\n",
    "    'viscos rayon': 6,\n",
    "    'regenerated fiber others': 7,\n",
    "    'polyester': 8,\n",
    "    'nylon': 9,\n",
    "    'polyurethane': 10,\n",
    "    'synthetic fiber others': 11,\n",
    "}\n",
    "methods = {\n",
    "    # washing method\n",
    "    'hand washing30': 0,\n",
    "    'washing30': 1,\n",
    "    'washing40': 2,\n",
    "    'washing60': 3,\n",
    "    'washing95': 4,\n",
    "                        \n",
    "    # drycleaning\n",
    "    'dryclean': 5,\n",
    "    'dryclean : laundry': 6,\n",
    "    'dryclean : petroleum solvent only': 7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda57813-020a-48da-ab3d-bfe7b21713ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 1\n",
    "def convert(label, bbox):\n",
    "    fiber_composition = list(set(label['fiber_composition'].split(\",\")))\n",
    "    washing_method = label['washing_method'].lower().strip()\n",
    "    drycleaning = label['drycleaning'].lower().strip()\n",
    "    bbox_str = \" \".join([str(bbox[0]), str(bbox[1]), str(bbox[2]), str(bbox[3])])\n",
    "    \n",
    "    txt = \"\"\n",
    "    nr_methods = len(methods)\n",
    "    for fiber in fiber_composition:\n",
    "        f = fiber.lower().strip()\n",
    "        if washing_method != 'do not washing' and washing_method != 'none':\n",
    "            washing_method = 'washing40' if washing_method == 'washing40_1' else washing_method\n",
    "            m = washing_method\n",
    "        else:\n",
    "            m = drycleaning\n",
    "        txt += str(nr_methods * fibers[f] + methods[m]) + \" \" + bbox_str + \"\\n\"\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbb9066-15eb-45d6-8051-81c57cdd74a9",
   "metadata": {},
   "source": [
    "# Version 2: ordinary object detection of multi-label classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf292e34-89e3-4acd-abaa-0ffbfd1b98b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 2/3: individual classes\n",
    "methods = {\n",
    "    # fiber composition\n",
    "    'cotton': 0,\n",
    "    'hemp': 1,\n",
    "    'cellulose fiber others': 2,\n",
    "    'silk': 3,\n",
    "    'wool': 4,\n",
    "    'protein fiber others': 5,\n",
    "    'viscos rayon': 6,\n",
    "    'regenerated fiber others': 7,\n",
    "    'polyester': 8,\n",
    "    'nylon': 9,\n",
    "    'polyurethane': 10,\n",
    "    'synthetic fiber others': 11,\n",
    "    \n",
    "    # washing method\n",
    "    'hand washing30': 12,\n",
    "    'washing30': 13,\n",
    "    'washing40': 14,\n",
    "    'washing60': 15,\n",
    "    'washing95': 16,\n",
    "                        \n",
    "    # drycleaning\n",
    "    'dryclean': 17,\n",
    "    'dryclean : laundry': 18,\n",
    "    'dryclean : petroleum solvent only': 19\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "635ffd1f-71b0-4ca8-b32d-b6a6174c66de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 2\n",
    "def convert(label, bbox):\n",
    "    fiber_composition = list(set(label['fiber_composition'].split(\",\")))\n",
    "    washing_method = label['washing_method'].lower().strip()\n",
    "    drycleaning = label['drycleaning'].lower().strip()\n",
    "    bbox_str = ' '.join([str(bbox[0]), str(bbox[1]), str(bbox[2]), str(bbox[3])])\n",
    "    \n",
    "    txt = ''\n",
    "    if washing_method != 'do not washing' and washing_method != 'none':\n",
    "        washing_method = 'washing40' if washing_method == 'washing40_1' else washing_method\n",
    "        m = washing_method\n",
    "    else:\n",
    "        m = drycleaning\n",
    "    txt += str(methods[m]) + ' ' + bbox_str + '\\n'\n",
    "    for fiber in fiber_composition:\n",
    "        f = fiber.lower().strip()\n",
    "        txt += str(methods[f]) + ' ' + bbox_str + '\\n'\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431344cc-b7b3-46f3-b435-9e22ad790a73",
   "metadata": {},
   "source": [
    "# Version 3: Multi-label object detection (not supported by YOLOv8 now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e795ec9a-25b6-481d-b069-874154c6c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 3\n",
    "def convert(label, bbox):\n",
    "    fiber_composition = list(set(label['fiber_composition'].split(\",\")))\n",
    "    washing_method = label['washing_method'].lower().strip()\n",
    "    drycleaning = label['drycleaning'].lower().strip()\n",
    "    bbox_str = ' '.join([str(bbox[0]), str(bbox[1]), str(bbox[2]), str(bbox[3])])\n",
    "    \n",
    "    txt = ''\n",
    "    if washing_method != 'do not washing' and washing_method != 'none':\n",
    "        washing_method = 'washing40' if washing_method == 'washing40_1' else washing_method\n",
    "        m = washing_method\n",
    "    else:\n",
    "        m = drycleaning\n",
    "    txt += str(methods[m]) + ' ' + bbox_str + ' '\n",
    "    for fiber in fiber_composition:\n",
    "        f = fiber.lower().strip()\n",
    "        txt += str(methods[f]) + ' '\n",
    "    txt += '\\n'\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c641de-c97f-4a84-8bc7-a05424a6f0bf",
   "metadata": {},
   "source": [
    "# Version 4: Sequential training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e97fb70-e34d-45fc-9da3-d68ce49ce7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 4\n",
    "fibers = {\n",
    "    # fiber composition\n",
    "    'cotton': 0,\n",
    "    'hemp': 1,\n",
    "    'cellulose fiber others': 2,\n",
    "    'silk': 3,\n",
    "    'wool': 4,\n",
    "    'protein fiber others': 5,\n",
    "    'viscos rayon': 6,\n",
    "    'regenerated fiber others': 7,\n",
    "    'polyester': 8,\n",
    "    'nylon': 9,\n",
    "    'polyurethane': 10,\n",
    "    'synthetic fiber others': 11,\n",
    "}\n",
    "methods = {\n",
    "    # washing method\n",
    "    'hand washing30': 0,\n",
    "    'washing30': 1,\n",
    "    'washing40': 2,\n",
    "    'washing60': 3,\n",
    "    'washing95': 4,\n",
    "                        \n",
    "    # drycleaning\n",
    "    'dryclean': 5,\n",
    "    'dryclean : laundry': 6,\n",
    "    'dryclean : petroleum solvent only': 7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f6d5432-d34a-46b1-8997-a90642e5c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 4\n",
    "def convert(label, bbox, type):\n",
    "    if type == 'f':\n",
    "        return convertFibers(label, bbox)\n",
    "    elif type == 'm':\n",
    "        return convertMethods(label, bbox)\n",
    "    else:\n",
    "        exit(0)\n",
    "\n",
    "# for methods\n",
    "def convertMethods(label, bbox):\n",
    "    fiber_composition = list(set(label['fiber_composition'].split(\",\")))\n",
    "    washing_method = label['washing_method'].lower().strip()\n",
    "    drycleaning = label['drycleaning'].lower().strip()\n",
    "    bbox_str = ' '.join([str(bbox[0]), str(bbox[1]), str(bbox[2]), str(bbox[3])])\n",
    "    \n",
    "    txt = ''\n",
    "    if washing_method != 'do not washing' and washing_method != 'none':\n",
    "        washing_method = 'washing40' if washing_method == 'washing40_1' else washing_method\n",
    "        m = washing_method\n",
    "    else:\n",
    "        m = drycleaning\n",
    "    txt += str(methods[m]) + ' ' + bbox_str + '\\n'\n",
    "    \n",
    "    return txt\n",
    "\n",
    "# for fibers\n",
    "def convertFibers(label, bbox):\n",
    "    fiber_composition = list(set(label['fiber_composition'].split(\",\")))\n",
    "    washing_method = label['washing_method'].lower().strip()\n",
    "    drycleaning = label['drycleaning'].lower().strip()\n",
    "    bbox_str = ' '.join([str(bbox[0]), str(bbox[1]), str(bbox[2]), str(bbox[3])])\n",
    "    \n",
    "    txt = ''\n",
    "    for fiber in fiber_composition:\n",
    "        f = fiber.lower().strip()\n",
    "        txt += str(fibers[f]) + ' ' + bbox_str + '\\n'\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bdb226c3-c802-44b5-b34d-e10da72df2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveAllTextLabels(labels: dict):\n",
    "    for root, label in labels:\n",
    "        idx = root.rfind('/', 0, len(root) - 1)\n",
    "        labelset_path = root[:idx] + '/'\n",
    "        directory_name = root[idx + 1: len(root) - 1]\n",
    "        \n",
    "        type = 'TL' if 'TL' in directory_name else 'VL'\n",
    "        bucketDir = labelset_path + type + '_txt/'\n",
    "        txtDir = bucketDir + directory_name + '_txt/'\n",
    "        # If the path to contain directories including text files doesn't exist, create it.\n",
    "        if not os.path.exists(bucketDir):\n",
    "            os.makedirs(bucketDir)\n",
    "        # If the path to store text files doesn't exist, create it.\n",
    "        if not os.path.exists(txtDir):\n",
    "            os.makedirs(txtDir)\n",
    "        # Write them in the text path.\n",
    "        id, name = label['id'], label['name']\n",
    "        path = txtDir + name + \".txt\"\n",
    "        with open(path, 'w') as f:\n",
    "            width, height = label['width'], label['height']\n",
    "            annotation = label['annotation'][0]\n",
    "            points, point_count = annotation['annotation_point'], annotation['annotation_point_count']\n",
    "            txt = convert(label, bbox(points, point_count, width, height))\n",
    "            f.write(txt)\n",
    "\n",
    "def saveAllTextLabelsInOne(labels: dict, version = None):\n",
    "    for root, label in labels:\n",
    "        type = 'train' if 'train' in root else 'val'\n",
    "        path = root[:root.find(type)] + type + '/reduced/'\n",
    "        # If the path to store text files doesn't exist, create it.\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        # Write them in the path.\n",
    "        id, name = label['id'], label['name']\n",
    "        with open(path + name + \".txt\", 'w') as f:\n",
    "            width, height = label['width'], label['height']\n",
    "            annotation = label['annotation'][0]\n",
    "            points, point_count = annotation['annotation_point'], annotation['annotation_point_count']\n",
    "            if version is None:\n",
    "                txt = convert(label, bbox(points, point_count, width, height))\n",
    "            else:\n",
    "                txt = convert(label, bbox(points, point_count, width, height), version)\n",
    "            f.write(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffcfc936-3992-47e7-835b-2be19226916b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186225\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43411a52-9568-461f-acf8-e13630d5815c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start converting all json files in ./../dataset/labels/\n",
      "Finish converting all json files in ./../dataset/labels/, elapsed = 92.41 sec(s)\n"
     ]
    }
   ],
   "source": [
    "root = './../dataset/labels/'\n",
    "print(f\"Start converting all json files in {root}\")\n",
    "start = time()\n",
    "with os.scandir(root) as dirs:\n",
    "    for dir in dirs:\n",
    "        if os.path.isdir(dir) and (dir.name == \"train\" or dir.name == \"val\"):\n",
    "            saveAllTextLabelsInOne(labels, 'm')\n",
    "end = time()\n",
    "print(f\"Finish converting all json files in {root}, elapsed = {end - start:.2f} sec(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee35f1a9-3bdb-462d-902b-ccd688e8a3aa",
   "metadata": {},
   "source": [
    "# Create a yaml file based on the class list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76174817-b7e9-464d-b584-f665c07e7aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'names': ['cotton/hand washing30',\n",
       "  'cotton/washing30',\n",
       "  'cotton/washing40',\n",
       "  'cotton/washing60',\n",
       "  'cotton/washing95',\n",
       "  'cotton/dryclean',\n",
       "  'cotton/dryclean : laundry',\n",
       "  'cotton/dryclean : petroleum solvent only',\n",
       "  'hemp/hand washing30',\n",
       "  'hemp/washing30',\n",
       "  'hemp/washing40',\n",
       "  'hemp/washing60',\n",
       "  'hemp/washing95',\n",
       "  'hemp/dryclean',\n",
       "  'hemp/dryclean : laundry',\n",
       "  'hemp/dryclean : petroleum solvent only',\n",
       "  'cellulose fiber others/hand washing30',\n",
       "  'cellulose fiber others/washing30',\n",
       "  'cellulose fiber others/washing40',\n",
       "  'cellulose fiber others/washing60',\n",
       "  'cellulose fiber others/washing95',\n",
       "  'cellulose fiber others/dryclean',\n",
       "  'cellulose fiber others/dryclean : laundry',\n",
       "  'cellulose fiber others/dryclean : petroleum solvent only',\n",
       "  'silk/hand washing30',\n",
       "  'silk/washing30',\n",
       "  'silk/washing40',\n",
       "  'silk/washing60',\n",
       "  'silk/washing95',\n",
       "  'silk/dryclean',\n",
       "  'silk/dryclean : laundry',\n",
       "  'silk/dryclean : petroleum solvent only',\n",
       "  'wool/hand washing30',\n",
       "  'wool/washing30',\n",
       "  'wool/washing40',\n",
       "  'wool/washing60',\n",
       "  'wool/washing95',\n",
       "  'wool/dryclean',\n",
       "  'wool/dryclean : laundry',\n",
       "  'wool/dryclean : petroleum solvent only',\n",
       "  'protein fiber others/hand washing30',\n",
       "  'protein fiber others/washing30',\n",
       "  'protein fiber others/washing40',\n",
       "  'protein fiber others/washing60',\n",
       "  'protein fiber others/washing95',\n",
       "  'protein fiber others/dryclean',\n",
       "  'protein fiber others/dryclean : laundry',\n",
       "  'protein fiber others/dryclean : petroleum solvent only',\n",
       "  'viscos rayon/hand washing30',\n",
       "  'viscos rayon/washing30',\n",
       "  'viscos rayon/washing40',\n",
       "  'viscos rayon/washing60',\n",
       "  'viscos rayon/washing95',\n",
       "  'viscos rayon/dryclean',\n",
       "  'viscos rayon/dryclean : laundry',\n",
       "  'viscos rayon/dryclean : petroleum solvent only',\n",
       "  'regenerated fiber others/hand washing30',\n",
       "  'regenerated fiber others/washing30',\n",
       "  'regenerated fiber others/washing40',\n",
       "  'regenerated fiber others/washing60',\n",
       "  'regenerated fiber others/washing95',\n",
       "  'regenerated fiber others/dryclean',\n",
       "  'regenerated fiber others/dryclean : laundry',\n",
       "  'regenerated fiber others/dryclean : petroleum solvent only',\n",
       "  'polyester/hand washing30',\n",
       "  'polyester/washing30',\n",
       "  'polyester/washing40',\n",
       "  'polyester/washing60',\n",
       "  'polyester/washing95',\n",
       "  'polyester/dryclean',\n",
       "  'polyester/dryclean : laundry',\n",
       "  'polyester/dryclean : petroleum solvent only',\n",
       "  'nylon/hand washing30',\n",
       "  'nylon/washing30',\n",
       "  'nylon/washing40',\n",
       "  'nylon/washing60',\n",
       "  'nylon/washing95',\n",
       "  'nylon/dryclean',\n",
       "  'nylon/dryclean : laundry',\n",
       "  'nylon/dryclean : petroleum solvent only',\n",
       "  'polyurethane/hand washing30',\n",
       "  'polyurethane/washing30',\n",
       "  'polyurethane/washing40',\n",
       "  'polyurethane/washing60',\n",
       "  'polyurethane/washing95',\n",
       "  'polyurethane/dryclean',\n",
       "  'polyurethane/dryclean : laundry',\n",
       "  'polyurethane/dryclean : petroleum solvent only',\n",
       "  'synthetic fiber others/hand washing30',\n",
       "  'synthetic fiber others/washing30',\n",
       "  'synthetic fiber others/washing40',\n",
       "  'synthetic fiber others/washing60',\n",
       "  'synthetic fiber others/washing95',\n",
       "  'synthetic fiber others/dryclean',\n",
       "  'synthetic fiber others/dryclean : laundry',\n",
       "  'synthetic fiber others/dryclean : petroleum solvent only'],\n",
       " 'nc': 96,\n",
       " 'path': '../dataset/',\n",
       " 'train': '/images/train/reduced/',\n",
       " 'val': '/images/val/reduced/'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Version 1\n",
    "import yaml\n",
    "\n",
    "fibers = ['cotton', 'hemp', 'cellulose fiber others',\n",
    "          'silk', 'wool', 'protein fiber others',\n",
    "          'viscos rayon', 'regenerated fiber others', 'polyester',\n",
    "          'nylon', 'polyurethane', 'synthetic fiber others']\n",
    "methods = ['hand washing30', 'washing30', 'washing40', 'washing60', 'washing95',\n",
    "           'dryclean', 'dryclean : laundry', 'dryclean : petroleum solvent only']\n",
    "\n",
    "names = []\n",
    "for f in fibers:\n",
    "    for m in methods:\n",
    "        names.append(f + '/' + m)\n",
    "\n",
    "data = {\n",
    "    'train': os.getcwd() + '/dataset/images/train/reduced/',\n",
    "    'val': os.getcwd() + '/dataset/images/val/reduced/',\n",
    "    'names': names,\n",
    "    'nc': len(names)\n",
    "}\n",
    "\n",
    "with open('./dataset/data.yaml', 'w') as f:\n",
    "    yaml.dump(data, f)\n",
    "\n",
    "with open('./dataset/data.yaml', 'r') as f:\n",
    "    cls = yaml.safe_load(f)\n",
    "    display(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "777a8af2-7f59-4b1b-9632-49d9f80818f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'names': ['cotton',\n",
       "  'hemp',\n",
       "  'cellulose fiber others',\n",
       "  'silk',\n",
       "  'wool',\n",
       "  'protein fiber others',\n",
       "  'viscos rayon',\n",
       "  'regenerated fiber others',\n",
       "  'polyester',\n",
       "  'nylon',\n",
       "  'polyurethane',\n",
       "  'synthetic fiber others',\n",
       "  'hand washing30',\n",
       "  'washing30',\n",
       "  'washing40',\n",
       "  'washing60',\n",
       "  'washing95',\n",
       "  'dryclean',\n",
       "  'dryclean : laundry',\n",
       "  'dryclean : petroleum solvent only'],\n",
       " 'nc': 20,\n",
       " 'train': 'd:\\\\source\\\\jupyter\\\\course\\\\project/dataset/images/train/reduced/',\n",
       " 'val': 'd:\\\\source\\\\jupyter\\\\course\\\\project/dataset/images/val/reduced/'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Version 2/3\n",
    "import yaml\n",
    "\n",
    "fibers = ['cotton', 'hemp', 'cellulose fiber others',\n",
    "          'silk', 'wool', 'protein fiber others',\n",
    "          'viscos rayon', 'regenerated fiber others', 'polyester',\n",
    "          'nylon', 'polyurethane', 'synthetic fiber others']\n",
    "methods = ['hand washing30', 'washing30', 'washing40', 'washing60', 'washing95',\n",
    "           'dryclean', 'dryclean : laundry', 'dryclean : petroleum solvent only']\n",
    "names = fibers + methods\n",
    "\n",
    "data = {\n",
    "    'train': os.getcwd() + '/dataset/images/train/resampled/',\n",
    "    'val': os.getcwd() + '/dataset/images/val/resampled/',\n",
    "    'names': names,\n",
    "    'nc': len(names),\n",
    "}\n",
    "\n",
    "with open('./dataset/data.yaml', 'w') as f:\n",
    "    yaml.dump(data, f)\n",
    "\n",
    "with open('./dataset/data.yaml', 'r') as f:\n",
    "    cls = yaml.safe_load(f)\n",
    "    display(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cffe28e-01cf-4ac7-8b01-18b0187e101a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'names': ['cotton',\n",
       "  'hemp',\n",
       "  'cellulose fiber others',\n",
       "  'silk',\n",
       "  'wool',\n",
       "  'protein fiber others',\n",
       "  'viscos rayon',\n",
       "  'regenerated fiber others',\n",
       "  'polyester',\n",
       "  'nylon',\n",
       "  'polyurethane',\n",
       "  'synthetic fiber others'],\n",
       " 'nc': 12,\n",
       " 'train': 'D:\\\\source\\\\jupyter\\\\course\\\\project\\\\conversion/../dataset/images/train/resampled/',\n",
       " 'val': 'D:\\\\source\\\\jupyter\\\\course\\\\project\\\\conversion/../dataset/images/val/resampled/'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'names': ['hand washing30',\n",
       "  'washing30',\n",
       "  'washing40',\n",
       "  'washing60',\n",
       "  'washing95',\n",
       "  'dryclean',\n",
       "  'dryclean : laundry',\n",
       "  'dryclean : petroleum solvent only'],\n",
       " 'nc': 8,\n",
       " 'train': 'D:\\\\source\\\\jupyter\\\\course\\\\project\\\\conversion/../dataset/images/train/resampled/',\n",
       " 'val': 'D:\\\\source\\\\jupyter\\\\course\\\\project\\\\conversion/../dataset/images/val/resampled/'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Version 4: sequential training (fiber -> method / method -> fiber)\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "fibers = ['cotton', 'hemp', 'cellulose fiber others',\n",
    "          'silk', 'wool', 'protein fiber others',\n",
    "          'viscos rayon', 'regenerated fiber others', 'polyester',\n",
    "          'nylon', 'polyurethane', 'synthetic fiber others']\n",
    "methods = ['hand washing30', 'washing30', 'washing40', 'washing60', 'washing95',\n",
    "           'dryclean', 'dryclean : laundry', 'dryclean : petroleum solvent only']\n",
    "\n",
    "fiber = {\n",
    "    'train': os.getcwd() + '/../dataset/images/train/resampled/',\n",
    "    'val': os.getcwd() + '/../dataset/images/val/resampled/',\n",
    "    'names': fibers,\n",
    "    'nc': len(fibers),\n",
    "}\n",
    "method = {\n",
    "    'train': os.getcwd() + '/../dataset/images/train/resampled/',\n",
    "    'val': os.getcwd() + '/../dataset/images/val/resampled/',\n",
    "    'names': methods,\n",
    "    'nc': len(methods),\n",
    "}\n",
    "\n",
    "with open('./../dataset/fiber.yaml', 'w') as f:\n",
    "    yaml.dump(fiber, f)\n",
    "\n",
    "with open('./../dataset/fiber.yaml', 'r') as f:\n",
    "    cls = yaml.safe_load(f)\n",
    "    display(cls)\n",
    "\n",
    "with open('./../dataset/method.yaml', 'w') as f:\n",
    "    yaml.dump(method, f)\n",
    "\n",
    "with open('./../dataset/method.yaml', 'r') as f:\n",
    "    cls = yaml.safe_load(f)\n",
    "    display(cls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
