{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "513abbc6-df4d-45b0-8e25-8ddaded4f734",
   "metadata": {},
   "source": [
    "## Reduce the original labels into ones with necessary fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee7d2c27-c13f-4ce9-adf5-3557aaa98a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5462c2c-bf3c-4d88-bf37-2c1457706419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadLabelsFrom(path):\n",
    "    if os.path.isdir(path) and not \"_reduced\" in path:\n",
    "        with os.scandir(path) as entries:\n",
    "            labels = []\n",
    "            start = time()\n",
    "            print(f\"Load all json files in '{path}'\")\n",
    "            for entry in entries:\n",
    "                if os.path.isfile(entry) and \".json\" in entry.name:\n",
    "                    with open(path + entry.name, 'r', encoding=\"UTF-8\") as file:\n",
    "                        json_object = json.load(file)\n",
    "                        # Drop out any jsons based on our criteria.\n",
    "                        clothes = json_object['metadata.clothes']\n",
    "                        washing_method = clothes['metadata.clothes.washing_method']  # Do Not Washing: A, none: C \n",
    "                        drycleaning = clothes['metadata.clothes.drycleaning']  # DO NOT DRYCLEAN: B, none: D\n",
    "                        if not ((washing_method == 'Do Not Washing' or washing_method == 'none') and (drycleaning == 'DO NOT DRYCLEAN' or drycleaning == 'none')):\n",
    "                            # Create a label with necessary fields: id, name, width, height, annotation, fiber_composition, washing_method, and drycleaning.\n",
    "                            label = {\n",
    "                                'id': json_object['dataset']['dataset.id'],\n",
    "                                'name': json_object['dataset']['dataset.name'],\n",
    "                                'width': json_object['dataset']['dataset.width'],\n",
    "                                'height': json_object['dataset']['dataset.height'],\n",
    "                                'annotation': json_object['annotation'],\n",
    "                                'fiber_composition': json_object['metadata.clothes']['metadata.clothes.fiber_composition'],\n",
    "                                'washing_method': json_object['metadata.clothes']['metadata.clothes.washing_method'],\n",
    "                                'drycleaning': json_object['metadata.clothes']['metadata.clothes.drycleaning']\n",
    "                            }\n",
    "                            labels.append(label)\n",
    "        end = time()\n",
    "        print(f\"Finish loading all json files in '{path}', elapsed = {end - start:.2f} sec(s)\")\n",
    "        return labels\n",
    "    else:\n",
    "        error_msg = \"ASSERTION FAILED:\"\n",
    "        if not os.path.isdir(path):\n",
    "            error_msg += f\" Path to label files must be a directory!\\n\"\n",
    "        elif \"_reduced\" in path:\n",
    "            error_msg += f\" Can't load files from the directory {path} because it has reserved name '_reduced'\\n\"\n",
    "        raise AssertionError(error_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3c45037-59f1-47c1-8768-41643f69d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeLabelsIn(path, labels):\n",
    "    if labels is not None:\n",
    "        # Create a directory to write reduced json files in.\n",
    "        directory_index = path.rfind(\"/\", 0, len(path) - 2)\n",
    "        directory_name = path[directory_index + 1:len(path) - 1]\n",
    "        dest = path[:directory_index + 1] + directory_name + \"_reduced/\"\n",
    "        \n",
    "        if not os.path.exists(dest):\n",
    "            os.makedirs(dest)\n",
    "            \n",
    "        start = time()\n",
    "        print(f\"Write all json files in '{path}'\")\n",
    "        for label in labels:\n",
    "            json_object = json.dumps(label, indent = 4)\n",
    "            file_path = dest + label['name'] + '.json'\n",
    "            with open(file_path, 'w') as new_json:\n",
    "                new_json.write(json_object)\n",
    "        end = time()\n",
    "        print(f\"Finish writing all json files in '{path}', elapsed = {end - start:.2f} sec(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4aa7703-ddb4-46b4-b5b0-bd3f9803c2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start a batch process which converts all labels in './dataset/labels/' into reduced ones.\n",
      "--------------------------------------------------------------------------------------------------------------------\n",
      "Load all json files in './dataset/labels/train/TL_blouse/'\n",
      "Finish loading all json files in './dataset/labels/train/TL_blouse/', elapsed = 6.24 sec(s)\n",
      "Load all json files in './dataset/labels/train/TL_bottom/'\n",
      "Finish loading all json files in './dataset/labels/train/TL_bottom/', elapsed = 23.41 sec(s)\n",
      "Load all json files in './dataset/labels/train/TL_cardigan/'\n",
      "Finish loading all json files in './dataset/labels/train/TL_cardigan/', elapsed = 5.74 sec(s)\n",
      "Load all json files in './dataset/labels/train/TL_coat/'\n",
      "Finish loading all json files in './dataset/labels/train/TL_coat/', elapsed = 6.75 sec(s)\n",
      "Load all json files in './dataset/labels/train/TL_jacket/'\n",
      "Finish loading all json files in './dataset/labels/train/TL_jacket/', elapsed = 6.97 sec(s)\n",
      "Load all json files in './dataset/labels/train/TL_jumper/'\n",
      "Finish loading all json files in './dataset/labels/train/TL_jumper/', elapsed = 7.49 sec(s)\n",
      "Load all json files in './dataset/labels/train/TL_onepiece_dress/'\n",
      "Finish loading all json files in './dataset/labels/train/TL_onepiece_dress/', elapsed = 12.33 sec(s)\n",
      "Load all json files in './dataset/labels/train/TL_onepiece_jumpsuite/'\n",
      "Finish loading all json files in './dataset/labels/train/TL_onepiece_jumpsuite/', elapsed = 0.34 sec(s)\n",
      "Load all json files in './dataset/labels/train/TL_shirt/'\n",
      "Finish loading all json files in './dataset/labels/train/TL_shirt/', elapsed = 8.33 sec(s)\n",
      "Load all json files in './dataset/labels/train/TL_sweater/'\n",
      "Finish loading all json files in './dataset/labels/train/TL_sweater/', elapsed = 7.10 sec(s)\n",
      "Load all json files in './dataset/labels/train/TL_t-shirt/'\n",
      "Finish loading all json files in './dataset/labels/train/TL_t-shirt/', elapsed = 24.35 sec(s)\n",
      "Load all json files in './dataset/labels/train/TL_vest/'\n",
      "Finish loading all json files in './dataset/labels/train/TL_vest/', elapsed = 4.62 sec(s)\n",
      "Load all json files in './dataset/labels/val/VL_blouse/'\n",
      "Finish loading all json files in './dataset/labels/val/VL_blouse/', elapsed = 0.77 sec(s)\n",
      "Load all json files in './dataset/labels/val/VL_bottom/'\n",
      "Finish loading all json files in './dataset/labels/val/VL_bottom/', elapsed = 2.92 sec(s)\n",
      "Load all json files in './dataset/labels/val/VL_cardigan/'\n",
      "Finish loading all json files in './dataset/labels/val/VL_cardigan/', elapsed = 0.72 sec(s)\n",
      "Load all json files in './dataset/labels/val/VL_coat/'\n",
      "Finish loading all json files in './dataset/labels/val/VL_coat/', elapsed = 0.85 sec(s)\n",
      "Load all json files in './dataset/labels/val/VL_jacket/'\n",
      "Finish loading all json files in './dataset/labels/val/VL_jacket/', elapsed = 0.82 sec(s)\n",
      "Load all json files in './dataset/labels/val/VL_jumper/'\n",
      "Finish loading all json files in './dataset/labels/val/VL_jumper/', elapsed = 0.93 sec(s)\n",
      "Load all json files in './dataset/labels/val/VL_onepiece_dress/'\n",
      "Finish loading all json files in './dataset/labels/val/VL_onepiece_dress/', elapsed = 1.51 sec(s)\n",
      "Load all json files in './dataset/labels/val/VL_onepiece_jumpsuite/'\n",
      "Finish loading all json files in './dataset/labels/val/VL_onepiece_jumpsuite/', elapsed = 0.04 sec(s)\n",
      "Load all json files in './dataset/labels/val/VL_shirt/'\n",
      "Finish loading all json files in './dataset/labels/val/VL_shirt/', elapsed = 0.99 sec(s)\n",
      "Load all json files in './dataset/labels/val/VL_sweater/'\n",
      "Finish loading all json files in './dataset/labels/val/VL_sweater/', elapsed = 0.87 sec(s)\n",
      "Load all json files in './dataset/labels/val/VL_t-shirt/'\n",
      "Finish loading all json files in './dataset/labels/val/VL_t-shirt/', elapsed = 2.99 sec(s)\n",
      "Load all json files in './dataset/labels/val/VL_vest/'\n",
      "Finish loading all json files in './dataset/labels/val/VL_vest/', elapsed = 0.58 sec(s)\n"
     ]
    }
   ],
   "source": [
    "root = \"./dataset/labels/\"\n",
    "sets = os.scandir(root)\n",
    "print(f\"Start a batch process which converts all labels in '{root}' into reduced ones.\")\n",
    "print(f\"--------------------------------------------------------------------------------------------------------------------\")\n",
    "start = time()\n",
    "# Iterate through label sets of datasets.\n",
    "write_list = {}\n",
    "for set in sets:\n",
    "    sub_root = os.scandir(set)\n",
    "    # Store all items in the sets by key(path to write) and value(label info) mapping.\n",
    "    for item in sub_root:  # sub_root =: [train | val]\n",
    "        if os.path.isdir(item) and item.name != \"zip\":\n",
    "            path = root + set.name + \"/\" + item.name + \"/\"\n",
    "            write_list[path] = loadLabelsFrom(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a6d6880-7171-41fb-a4dd-3277cc70e8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write all json files in './dataset/labels/train/TL_blouse/'\n",
      "Finish writing all json files in './dataset/labels/train/TL_blouse/', elapsed = 4.18 sec(s)\n",
      "Write all json files in './dataset/labels/train/TL_bottom/'\n",
      "Finish writing all json files in './dataset/labels/train/TL_bottom/', elapsed = 12.85 sec(s)\n",
      "Write all json files in './dataset/labels/train/TL_cardigan/'\n",
      "Finish writing all json files in './dataset/labels/train/TL_cardigan/', elapsed = 3.71 sec(s)\n",
      "Write all json files in './dataset/labels/train/TL_coat/'\n",
      "Finish writing all json files in './dataset/labels/train/TL_coat/', elapsed = 5.45 sec(s)\n",
      "Write all json files in './dataset/labels/train/TL_jacket/'\n",
      "Finish writing all json files in './dataset/labels/train/TL_jacket/', elapsed = 4.88 sec(s)\n",
      "Write all json files in './dataset/labels/train/TL_jumper/'\n",
      "Finish writing all json files in './dataset/labels/train/TL_jumper/', elapsed = 6.06 sec(s)\n",
      "Write all json files in './dataset/labels/train/TL_onepiece_dress/'\n",
      "Finish writing all json files in './dataset/labels/train/TL_onepiece_dress/', elapsed = 7.11 sec(s)\n",
      "Write all json files in './dataset/labels/train/TL_onepiece_jumpsuite/'\n",
      "Finish writing all json files in './dataset/labels/train/TL_onepiece_jumpsuite/', elapsed = 0.20 sec(s)\n",
      "Write all json files in './dataset/labels/train/TL_shirt/'\n",
      "Finish writing all json files in './dataset/labels/train/TL_shirt/', elapsed = 7.16 sec(s)\n",
      "Write all json files in './dataset/labels/train/TL_sweater/'\n",
      "Finish writing all json files in './dataset/labels/train/TL_sweater/', elapsed = 5.08 sec(s)\n",
      "Write all json files in './dataset/labels/train/TL_t-shirt/'\n",
      "Finish writing all json files in './dataset/labels/train/TL_t-shirt/', elapsed = 19.97 sec(s)\n",
      "Write all json files in './dataset/labels/train/TL_vest/'\n",
      "Finish writing all json files in './dataset/labels/train/TL_vest/', elapsed = 4.21 sec(s)\n",
      "Write all json files in './dataset/labels/val/VL_blouse/'\n",
      "Finish writing all json files in './dataset/labels/val/VL_blouse/', elapsed = 0.61 sec(s)\n",
      "Write all json files in './dataset/labels/val/VL_bottom/'\n",
      "Finish writing all json files in './dataset/labels/val/VL_bottom/', elapsed = 2.04 sec(s)\n",
      "Write all json files in './dataset/labels/val/VL_cardigan/'\n",
      "Finish writing all json files in './dataset/labels/val/VL_cardigan/', elapsed = 0.59 sec(s)\n",
      "Write all json files in './dataset/labels/val/VL_coat/'\n",
      "Finish writing all json files in './dataset/labels/val/VL_coat/', elapsed = 0.83 sec(s)\n",
      "Write all json files in './dataset/labels/val/VL_jacket/'\n",
      "Finish writing all json files in './dataset/labels/val/VL_jacket/', elapsed = 0.76 sec(s)\n",
      "Write all json files in './dataset/labels/val/VL_jumper/'\n",
      "Finish writing all json files in './dataset/labels/val/VL_jumper/', elapsed = 0.89 sec(s)\n",
      "Write all json files in './dataset/labels/val/VL_onepiece_dress/'\n",
      "Finish writing all json files in './dataset/labels/val/VL_onepiece_dress/', elapsed = 1.09 sec(s)\n",
      "Write all json files in './dataset/labels/val/VL_onepiece_jumpsuite/'\n",
      "Finish writing all json files in './dataset/labels/val/VL_onepiece_jumpsuite/', elapsed = 0.03 sec(s)\n",
      "Write all json files in './dataset/labels/val/VL_shirt/'\n",
      "Finish writing all json files in './dataset/labels/val/VL_shirt/', elapsed = 0.87 sec(s)\n",
      "Write all json files in './dataset/labels/val/VL_sweater/'\n",
      "Finish writing all json files in './dataset/labels/val/VL_sweater/', elapsed = 0.65 sec(s)\n",
      "Write all json files in './dataset/labels/val/VL_t-shirt/'\n",
      "Finish writing all json files in './dataset/labels/val/VL_t-shirt/', elapsed = 2.53 sec(s)\n",
      "Write all json files in './dataset/labels/val/VL_vest/'\n",
      "Finish writing all json files in './dataset/labels/val/VL_vest/', elapsed = 0.56 sec(s)\n",
      "--------------------------------------------------------------------------------------------------------------------\n",
      "Finish a batch process which converts all labels in './dataset/labels/' into reduced ones, elapsed = 345.333197 sec(s).\n"
     ]
    }
   ],
   "source": [
    "# Write them into their corresponding paths.\n",
    "for path, item in write_list.items():\n",
    "    writeLabelsIn(path, item)\n",
    "end = time()\n",
    "print(f\"--------------------------------------------------------------------------------------------------------------------\")\n",
    "print(f\"Finish a batch process which converts all labels in '{root}' into reduced ones, elapsed = {end - start:.6f} sec(s).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
